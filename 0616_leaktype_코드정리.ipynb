{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0616_leaktype_코드정리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "-8qIDjPM8UEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## before(ifft) : raw data"
      ],
      "metadata": {
        "id": "FGi70GVO8i87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import collections\n",
        "from collections import Counter\n",
        "\n",
        "train = pd.read_csv('./leaktype_train.csv')\n",
        "#test = pd.read_csv('./leaktype_test.csv')\n",
        "X = np.array(train.drop('leaktype', axis=1))\n",
        "y = np.array(train.leaktype) # y완\n",
        "print(y[:10])\n",
        "print(X.shape)\n",
        "X_1d = X.reshape(1, -1) # normalization 위해 1-d 배열로 변경\n",
        "print(X_1d.shape)\n",
        "\n",
        "# X_1d\n",
        "\n",
        "# train 데이터 label 별 갯수 파악\n",
        "label_counts = collections.Counter(train['leaktype'])\n",
        "print('Counts by label:', dict(label_counts))\n",
        "print(f'Naive Accuracy: {100*max(label_counts.values())/sum(label_counts.values()):0.2f}%')"
      ],
      "metadata": {
        "id": "F3GMQTHe88BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data augmentation : before-aug"
      ],
      "metadata": {
        "id": "ELJWqdfm8mbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import collections\n",
        "from collections import Counter\n",
        "\n",
        "train = pd.read_csv('./leaktype_train.csv', header=0)\n",
        "\n",
        "leak_out = train[train.leaktype=='out'] # 10배\n",
        "leak_in = train[train.leaktype=='in'] # 10배\n",
        "leak_noise = train[train.leaktype=='noise'] # 3.6\n",
        "leak_other = train[train.leaktype=='other'] # 2.57\n",
        "\n",
        "noise_index = list(leak_noise.index)\n",
        "other_index = list(leak_other.index)\n",
        "noise_random_idx = list(np.random.choice(noise_index, 3000))\n",
        "other_random_idx = list(np.random.choice(other_index, 4000))\n",
        "\n",
        "noise_extra = leak_noise.loc[noise_random_idx]\n",
        "other_extra = leak_other.loc[other_random_idx]\n",
        "\n",
        "# 단순 복제하여 oversampling\n",
        "df_out = pd.concat([leak_out]*9, ignore_index=True)\n",
        "df_in = pd.concat([leak_in]*9, ignore_index=True)\n",
        "df_noise = pd.concat([leak_noise]*2, ignore_index=True)\n",
        "df_other = pd.concat([leak_other]*1, ignore_index=True)\n",
        "\n",
        "train_over = pd.concat([train, df_out, df_in, df_noise, df_other, noise_extra, other_extra], axis=0, ignore_index=True)\n",
        "\n",
        "# train_over\n",
        "\n",
        "#train_over.to_csv('./oversampled.csv')\n",
        "\n",
        "# label 수 확인\n",
        "label_counts = collections.Counter(train_over['leaktype'])\n",
        "print('Counts by label:', dict(label_counts))\n",
        "print(f'Naive Accuracy: {100*max(label_counts.values())/sum(label_counts.values()):0.2f}%')"
      ],
      "metadata": {
        "id": "fzlimWlo8ZUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generate after(ifft)"
      ],
      "metadata": {
        "id": "ioNKmQBV8xqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train = pd.read_csv('./leaktype_train.csv')\n",
        "\n",
        "X_tmp = train.drop('leaktype', axis=1)\n",
        "X_tmp = np.array(X_tmp)\n",
        "\n",
        "# generate after(ifft)\n",
        "X_ifft = np.fft.ifft(X_tmp)\n",
        "plt.plot(X_ifft[0]) # 데이터 확인\n",
        "\n",
        "X_ifft = X_ifft.real\n",
        "after = pd.DataFrame(X_ifft)\n",
        "\n",
        "# after"
      ],
      "metadata": {
        "id": "9T78QyS9BRt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## normalization"
      ],
      "metadata": {
        "id": "a7yOkl__83mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(X_1d.T)\n",
        "normalized_X = scaler.transform(X_1d.T).T\n",
        "norm_X = normalized_X.reshape((33600, 513)) # 데이터 별로 변경 필요\n",
        "norm_X = to3d(norm_X) # X완"
      ],
      "metadata": {
        "id": "HOhtzjDvAaT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "Z_PPTETDDDls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리한 데이터 X, y 준비 후 #\n",
        "\n",
        "# splits 생성\n",
        "X, y = norm_X, y\n",
        "\n",
        "model_name = 'InceptionTimePlus'\n",
        "data_type = 'before-aug' \n",
        "\n",
        "splits = get_splits(y, valid_size=0.2, stratify=True, random_state=42, shuffle=True) ################\n",
        "\n",
        "\n",
        "# prepare dataloaders\n",
        "tfms = [None, TSClassification()] # TSClassification == Categorize\n",
        "batch_tfms = TSStandardize()\n",
        "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=[64, 128])\n",
        "print(f'dls.dataset:\\n{dls.dataset}')\n",
        "dls.show_batch(sharey=True) # 데이터 그래프로 보여줌\n",
        "plt.show()\n",
        "\n",
        "# build learner\n",
        "model = build_ts_model(InceptionTimePlus, dls=dls) # model\n",
        "learn = Learner(dls, model, metrics=accuracy)\n",
        "\n",
        "# learning rate curve\n",
        "learn.lr_find()\n",
        "\n",
        "# train\n",
        "learn = ts_learner(dls, metrics=accuracy, cbs=ShowGraph())\n",
        "learn.fit_one_cycle(10, lr_max=1e-3)\n",
        "\n",
        "# 모델 저장\n",
        "PATH = Path(f'./models/{model_name}_{data_type}.pkl')\n",
        "PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "learn.export(PATH)\n",
        "\n",
        "# visualize data\n",
        "learn.show_results(sharey=True)\n",
        "learn.show_probas()\n",
        "\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()\n",
        "interp.most_confused(min_val=3)\n",
        "interp.print_classification_report()\n",
        "\n",
        "# create predictions\n",
        "PATH = Path(f'./models/{model_name}_{data_type}.pkl')\n",
        "learn_gpu = load_learner(PATH, cpu=False)\n",
        "probas, _, preds = learn_gpu.get_X_preds(X[splits[0]])\n",
        "print(preds[-10:])"
      ],
      "metadata": {
        "id": "p_nkNCudDGLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "ptq7IfXkDFN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "test =  pd.read_csv('./leaktype_test.csv', index_col=0, header=0)\n",
        "X_test = np.array(test)\n",
        "print(X_test.shape)\n",
        "\n",
        "X_1d = X_test.reshape(1,-1)\n",
        "print(X_1d.shape)\n",
        "\n",
        "# normalization\n",
        "scaler = joblib.load(f'./models/standard_scalar.pkl')\n",
        "normalized_X = scaler.transform(X_1d.T).T\n",
        "X_test = normalized_X.reshape((7820, 513))\n",
        "X_test.shape\n",
        "\n",
        "# to3d\n",
        "X_test = to3d(X_test)\n",
        "print(X_test.shape)\n",
        "\n",
        "# create predictions\n",
        "model_name = 'MiniRocket' # train에서 입력한거랑 같게\n",
        "data_type = 'before-aug'\n",
        "\n",
        "PATH = Path(f'./models/{model_name}_{data_type}.pkl')\n",
        "learn_gpu = load_learner(PATH, cpu=False)\n",
        "probas, _, preds = learn_gpu.get_X_preds(X_test)\n",
        "print(model_name)\n",
        "print(preds[-10:])\n",
        "print('-'*20)\n",
        "#preds.to_csv(f'./{model_name}_{data_type}_preds.csv')\n",
        "preds_df = pd.DataFrame(preds)\n",
        "print(preds_df.head(3))\n",
        "\n",
        "t_temp = test.reset_index()\n",
        "test_preds = pd.concat([t_temp[['id']], preds_df], axis=1, ignore_index=False)\n",
        "test_preds.rename(columns={0:'preds_label'}, inplace=True)\n",
        "print(test_preds.head(3))\n",
        "\n",
        "# test_preds\n",
        "\n",
        "#test_preds.to_csv(f'./{model_name}_{data_type}_preds.csv')"
      ],
      "metadata": {
        "id": "GpcVL24JDaUZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}